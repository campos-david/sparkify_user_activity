# Here it's where we are going to construct the code

# First, import the py packages

import pandas as pd
import cassandra
import re
import os
import glob
import numpy as np
import json
import csv

# Configure the right path and create the csv file that will be used to query the necessary tables

print(os.getcwd())
filepath = os.getcwd() + '/event_data'
for root, dirs, files in os.walk(filepath):
  file_path_list = glob.glob(os.path.join(root,'*'))
print(filepath)

full_data_rows_list = [] 
for f in file_path_list:
   with open(f, 'r', encoding = 'utf8', newline='') as csvfile:
    csvreader = csv.reader(csvfile) 
    next(csvreader)
    for line in csvreader:
      full_data_rows_list.append(line)

csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)

with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:
    writer = csv.writer(f, dialect='myDialect')
    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\
                'level','location','sessionId','song','userId'])
    for row in full_data_rows_list:
        if (row[0] == ''):
            continue
        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))

# check the number of rows in the csv file
with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:
    print(sum(1 for line in f))

# Create the cluster, connect to it and create the keyspace:

from cassandra.cluster import Cluster
cluster = Cluster()
session = cluster.connect()
session.execute("""
    CREATE KEYSPACE IF NOT EXISTS sparkify 
    WITH REPLICATION = 
    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }"""
               )
session.set_keyspace('sparkify')

# Tables created and schema defined, time to answer some business questions

# Question1: Give me the artist, song title and song's length in the music app history that was heard during sessionId = 338, and itemInSession = 4

query1table = """CREATE TABLE IF NOT EXISTS query1table
    (artist_name text,
    item_in_session int,
    length float,
    session_id int,
    song_title text,
    PRIMARY KEY (session_id, item_in_session)
)"""
session.execute(query1table)
file = 'event_datafile_new.csv'

with open(file, encoding = 'utf8') as f:
    csvreader = csv.reader(f)
    next(csvreader) # skip header
    for line in csvreader:
        query = "INSERT INTO query1table (artist_name, item_in_session, length, session_id, song_title)"
        query = query + "VALUES (%s, %s, %s, %s, %s)"
        session.execute(query, (line[0], int(line[3]), float(line[5]), int(line[8]), line[9]))

query = """SELECT * FROM query1table WHERE SESSION_ID = 338 AND ITEM_IN_SESSION = 4"""
result_set = session.execute(query)
for row in result_set:
    print(row)

# Results were: Row(session_id=338, item_in_session=4, artist_name='Faithless', length=495.30731201171875, song_title='Music Matters (Mark Knight Dub)')

# now, the question2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182

file = 'event_datafile_new.csv'

with open(file, encoding = 'utf8') as f:
    csvreader = csv.reader(f)
    next(csvreader) # skip header
    for line in csvreader:
       query2table = """
CREATE TABLE IF NOT EXISTS query2table (
    user_id int,
    session_id int,
    item_in_session int,
    artist_name text,
    song_title text,
    FirstName text,
    LastName text,
    PRIMARY KEY ((user_id, session_id), item_in_session)
) WITH CLUSTERING ORDER BY (item_in_session ASC);
"""
session.execute(query2table)


with open(file, encoding='utf8') as f:
    csvreader = csv.reader(f)
    next(csvreader)  # Skip header
    
    query2 = """
    INSERT INTO query2table (user_id, session_id, item_in_session, artist_name, song_title, FirstName, LastName)
    VALUES (%s, %s, %s, %s, %s, %s, %s)
    """
    
    for line in csvreader:
        session.execute(query2, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]))
query2 = """
SELECT artist_name, song_title, FirstName, LastName 
FROM query2table 
WHERE user_id = 10 AND session_id = 182;
"""
result_set2 = session.execute(query2)
for row in result_set2:
    print(row)

# Results were: Row(artist_name='Down To The Bone', song_title="Keep On Keepin' On", firstname='Sylvie', lastname='Cruz')
# Row(artist_name='Three Drives', song_title='Greece 2000', firstname='Sylvie', lastname='Cruz')
# Row(artist_name='Sebastien Tellier', song_title='Kilometer', firstname='Sylvie', lastname='Cruz')
# Row(artist_name='Lonnie Gordon', song_title='Catch You Baby (Steve Pitron & Max Sanna Radio Edit)', firstname='Sylvie', lastname='Cruz')

# Now, let's answer the last question, question3: 

file = 'event_datafile_new.csv'

with open(file, encoding = 'utf8') as f:
    csvreader = csv.reader(f)
    next(csvreader) # skip header
    for line in csvreader:
       query3table = """
CREATE TABLE IF NOT EXISTS query3table (
    user_id int,
    song_title text,
    FirstName text,
    LastName text,
    PRIMARY KEY (song_title, user_id)
)
"""
session.execute(query3table)


with open(file, encoding='utf8') as f:
    csvreader = csv.reader(f)
    next(csvreader)  # Skip header
    
    query3 = """
    INSERT INTO query3table (user_id, song_title, FirstName, LastName)
    VALUES (%s, %s, %s, %s)
    """
    
    for line in csvreader:
        session.execute(query3, (int(line[10]), line[9], line[1], line[4]))

query3 = """
SELECT FirstName, LastName 
FROM query3table 
WHERE SONG_TITLE = 'All Hands Against His Own'
"""
result_set3 = session.execute(query3)
for row in result_set3:
    print(row)

# Results were: Row(firstname='Jacqueline', lastname='Lynch')
# Row(firstname='Tegan', lastname='Levine')
# Row(firstname='Sara', lastname='Johnson')

# Now that is all answered, let's drop the tables and finish the connection

querydrop_table = """DROP TABLE query1table
"""

session.execute(querydrop_table)
querydrop_table = """DROP TABLE query2table
"""

session.execute(querydrop_table)
querydrop_table = """DROP TABLE query3table
"""

session.execute(querydrop_table)

session.shutdown()
cluster.shutdown()

# Tables created and schema defined, ready to answer any business question possible, it was fun and knowledgeful, contributed a lot to my understanding of Data Engineering, data modeling and schemas definition.
